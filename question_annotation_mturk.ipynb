{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Table of Contents\n",
    "* [Submitting HITs](#Submitting-HITs)\n",
    "\t* [Building URLs for images on s3](#Building-URLs-for-images-on-s3)\n",
    "\t* [submitting HITs in groups](#submitting-HITs-in-groups)\n",
    "\t\t* [creates HITs, careful with this one](#creates-HITs,-careful-with-this-one)\n",
    "* [Reviewing latest HITs](#Reviewing-latest-HITs)\n",
    "* [Merging latest round of HITs into combined dataset](#Merging-latest-round-of-HITs-into-combined-dataset)\n",
    "\t* [Load prior complete dataset if not in memory](#Load-prior-complete-dataset-if-not-in-memory)\n",
    "\t* [Updating full dataset](#Updating-full-dataset)\n",
    "\t* [Working with full dataset](#Working-with-full-dataset)\n",
    "* [Worker Analysis](#Worker-Analysis)\n",
    "\t* [Basic worker stats](#Basic-worker-stats)\n",
    "\t\t* [HIT duration for pricing](#HIT-duration-for-pricing)\n",
    "\t\t* [Identifying high and low consensus workers](#Identifying-high-and-low-consensus-workers)\n",
    "\t* [Messaging workers](#Messaging-workers)\n",
    "* [HIT end-of-life](#HIT-end-of-life)\n",
    "\t* [Pickle latest results](#Pickle-latest-results)\n",
    "\t* [Pickle combined dataset](#Pickle-combined-dataset)\n",
    "\t* [Accepting and deleting HITs... careful with these](#Accepting-and-deleting-HITs...-careful-with-these)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import itertools\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pylab as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext base16_mplrc\n",
    "%base16_mplrc light default\n",
    "plt.rcParams['figure.figsize'] = (16.0, 10.0)\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import dateutil.parser as dt_parse\n",
    "import pickle\n",
    "import boto\n",
    "import json\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "import boto.mturk.connection as tc\n",
    "import boto.mturk.question as tq\n",
    "from boto.mturk.qualification import PercentAssignmentsApprovedRequirement, Qualifications, Requirement\n",
    "\n",
    "from keysTkingdom import mturk_ai2\n",
    "from keysTkingdom import aws_tokes\n",
    "\n",
    "import pdfextraction.amt_boto_modules as amt_util\n",
    "import pdfextraction.turk_email_utils as turkmail_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Submitting HITs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building URLs for images on s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "book_groups, ranges = amt_util.load_book_info()\n",
    "\n",
    "daily_sci_urls = amt_util.make_book_group_urls(book_groups, 'daily_sci', ranges)\n",
    "spectrum_sci_urls = amt_util.make_book_group_urls(book_groups, 'spectrum_sci', ranges)\n",
    "read_und_sci_urls  = amt_util.make_book_group_urls(book_groups, 'read_und_sci', ranges)\n",
    "workbook_urls = amt_util.make_book_group_urls(book_groups, 'workbooks', ranges)\n",
    "misc_urls = amt_util.make_book_group_urls(book_groups, 'misc', ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "len(daily_sci_urls + spectrum_sci_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "combined_df_question_pages_only = pd.read_pickle('pages_w_questions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pages_w_questions = pd.unique(combined_df_question_pages_only['page'])\n",
    "len(pages_w_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "question_specific_urls = [url for url in spectrum_sci_urls if url.split('=')[1].split('&')[0] in pages_w_questions]\n",
    "len(question_specific_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submitting HITs in groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DON'T FORGET to change submission POST request in the client when changing host**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## Switch between sandbox and the real world here ##\n",
    "## DON'T FORGET to change submission POST request in the client ##\n",
    "\n",
    "sandbox_host = 'mechanicalturk.sandbox.amazonaws.com' \n",
    "real_world_host = 'mechanicalturk.amazonaws.com'\n",
    "mturk = tc.MTurkConnection(\n",
    "    aws_access_key_id = aws_tokes.access_key,\n",
    "    aws_secret_access_key = aws_tokes.access_secret_key,\n",
    "    host = real_world_host,\n",
    "    debug = 1 # debug = 2 prints out all requests.\n",
    ")\n",
    "current_account_balance = mturk.get_account_balance()[0]\n",
    "if current_account_balance.amount == 10000:\n",
    "    print \"Working in the SANDBOX with\"\n",
    "else:\n",
    "    print \"Working in the REAL WORLD with\"\n",
    "print current_account_balance # a reminder of sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "static_params = {\n",
    "    'title': \"Annotate Science Questions\",\n",
    "    'description': \"Choose which category questions from a grade-school science book best belong to\",\n",
    "    'keywords': ['image', 'science', 'text', 'labeling' ],\n",
    "    'frame_height': 800,\n",
    "    'amount': 0.06,\n",
    "    'duration': 3600 * 12,\n",
    "    'lifetime': 3600 * 24 * 3,\n",
    "    'max_assignments': 1   # change to 3 when running irl\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creates HITs, careful with this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pages_to_use = question_specific_urls[20:22]\n",
    "expected_cost = len(pages_to_use) *  static_params['amount'] * static_params['max_assignments']\n",
    "if float(current_account_balance.amount) < expected_cost:\n",
    "    print('WARNING -- account balance is too low -- WARNING')\n",
    "print('expect this batch of HITs to cost: $' + str(expected_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**uncomment cell below only when ready to submit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# amt_util.create_hits_from_pages(mturk, pages_to_use, static_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Qualifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "new_qual_name = 'science textbook annotation'\n",
    "new_qual_description = 'Qualification for workers who have proved to be good at annotating science textbooks'\n",
    "# my_qual_type = mturk.create_qualification_type(new_qual_name, new_qual_description, status='Active')\n",
    "\n",
    "my_qual_type = mturk.search_qualification_types(new_qual_name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "my_qual_id = my_qual_type.QualificationTypeId\n",
    "print my_qual_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "mturk.assign_qualification(my_qual_id, worker_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reviewing HITs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving and processing latest HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "r_hits_current_batch = amt_util.get_completed_hits(mturk)\n",
    "assignment_results_current_batch = amt_util.get_assignments(mturk, r_hits_current_batch, 'Submitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "raw_hit_results_current_batch = amt_util.process_raw_hits(assignment_results_current_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "amt_util.get_assignment_statuses(assignment_results_current_batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commands above interact with mechanical turk and can take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "results_df_question_batch = amt_util.make_question_results_df(raw_hit_results_current_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "consensus_results_df_current_batch = amt_util.make_consensus_df(results_df_question_batch, 'No Consensus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "question_cats = ['Multiple Choice',\n",
    "                 'Fill-in-the-Blank',\n",
    "                 'Short Answer',\n",
    "                 'Discussion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "question_only_cons_df = consensus_results_df_current_batch[consensus_results_df_current_batch['box_id'].apply(lambda x:x[0] == 'Q' ) | consensus_results_df_current_batch['category'].isin(question_cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "no_consensus_hits_cat = consensus_results_df_current_batch[consensus_results_df_current_batch['category'] == 'No Consensus']\n",
    "\n",
    "flaw_rate = len(no_consensus_hits_cat) / len(consensus_results_df_current_batch)\n",
    "print 'question boxes without category consensus comprise ' + '{0:0.2f}% '.format(flaw_rate * 100) + 'of the total'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers differ because-\n",
    "1. The first counts non-con results from the first round (non-question results)\n",
    "\n",
    "2. The second counts only boxes either previously marked as a question, or selected in ths round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "no_consensus_hits_cat = question_only_cons_df[question_only_cons_df['category'] == 'No Consensus']\n",
    "\n",
    "flaw_rate = len(no_consensus_hits_cat) / len(question_only_cons_df)\n",
    "print 'question boxes without category consensus comprise ' + '{0:0.2f}% '.format(flaw_rate * 100) + 'of the total'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amt_util.write_results_df(consensus_results_df_current_batch, 'annotations-w-questions/', 'simpler-test-questions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# consensus_results_df_current_batch[consensus_results_df_current_batch['page'] == 'Spectrum_Science_Grade_8_8.jpeg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **sending to review tool**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### randomly sampling HITs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pages_to_review = np.unique(consensus_results_df_current_batch['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "sampling_rate = 0.1\n",
    "sample_size = int(len(pages_to_review) * sampling_rate)\n",
    "sampled_pages_to_review = list(np.random.choice(pages_to_review, size= sample_size, replace=False))\n",
    "print 'sampling ' + str(sample_size) + ' pages out of ' + str(len(pages_to_review))\n",
    "to_review = ['start_seq'] + sampled_pages_to_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "anno_dir = 'simpler-test-questions/'\n",
    "amt_util.review_results(to_review, anno_dir)\n",
    "print 'posting to review tool, navigate to http://localhost:8080/ to see the sampled consensus results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### sampling no consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pages_to_review =pd.unique(no_consensus_hits_cat['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "sampling_rate = 0.5\n",
    "sample_size = int(len(pages_to_review) * sampling_rate)\n",
    "sampled_pages_to_review = list(np.random.choice(pages_to_review, size= sample_size, replace=False))\n",
    "print 'sampling ' + str(sample_size) + ' pages out of ' + str(len(pages_to_review))\n",
    "to_review = ['start_seq'] + sampled_pages_to_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "anno_dir = 'simpler-test-questions/'\n",
    "amt_util.review_results(to_review, anno_dir)\n",
    "print 'posting to review tool, navigate to http://localhost:8080/ to see the sampled consensus results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looking at individual workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ind_worker_dir = 'individual-worker-results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_and_prolific_to_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# workers_to_review = turkers_contacted_me[:1]\n",
    "workers_to_review = really_bad_workers_to_review\n",
    "subset_by_worker = results_df_question_batch[results_df_question_batch['worker_id'].isin(workers_to_review)]\n",
    "\n",
    "amt_util.write_results_df(subset_by_worker, 'annotations-w-questions/', ind_worker_dir)\n",
    "pages_to_review = pd.unique(subset_by_worker['page']).tolist()\n",
    "to_review = ['start_seq'] + pages_to_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "anno_dir = ind_worker_dir\n",
    "amt_util.review_results(to_review, anno_dir)\n",
    "print 'posting to review tool, navigate to http://localhost:8080/ to see the sampled consensus results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### store cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "multi_choice_pages = consensus_results_df_complete[consensus_results_df_complete['category'] == 'Multiple Choice']\n",
    "pages_to_review =pd.unique(multi_choice_pages['page'])\n",
    "to_review = ['start_seq'] + pages_to_review.tolist()\n",
    "\n",
    "# consensus_results_df_complete = amt_util.make_consensus_df(results_df_question_batch, 'No Consensus')\n",
    "consensus_results_df_complete = combined_consensus_df\n",
    "\n",
    "# amt_util.write_results_df(consensus_results_df_complete, 'annotations-w-questions/' ,'labeled-questions/')\n",
    "\n",
    "spdf = results_df_question_batch[results_df_question_batch['page'] == 'Spectrum_Science_Grade_3_80.jpeg']\n",
    "\n",
    "amt_util.write_results_df(spdf, 'annotations-w-questions/', 'simpler-test-questions/')\n",
    "\n",
    "## all pages from the latest batch\n",
    "pages_to_review =pd.unique(consensus_results_df_complete['page'])\n",
    "to_review = ['start_seq'] + pages_to_review.tolist()\n",
    "\n",
    "# all pages from the latest batch with a no-consensus box\n",
    "# pages_to_review =pd.unique(no_consensus_hits['page'])\n",
    "\n",
    "pd.Series(to_review[1:]).to_pickle('rev_seq.pkl')\n",
    "\n",
    "single_page = ['Daily_Science_Grade_2_Evan_Moor_33.jpeg']\n",
    "\n",
    "problem_pages = pd.read_pickle('problem_pages.pkl').tolist()\n",
    "\n",
    "to_review = ['start_seq'] + problem_pages\n",
    "\n",
    "to_review = ['start_seq'] + single_page\n",
    "\n",
    "suspect_subset = combined_results_df[combined_results_df['worker_id'].isin(bad_and_prolific_to_review)]\n",
    "# suspect_subset = combined_results_df[combined_results_df['worker_id'].isin(['A3VE5OH94HYHET'])]\n",
    "amt_util.write_results_df(suspect_subset, 'annotations-w-questions/' ,'labeled-questions2/')\n",
    "pages_to_review = pd.unique(suspect_subset['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## all pages from the latest batch\n",
    "pages_to_review =pd.unique(results_df_question_batch['page'])\n",
    "to_review = ['start_seq'] + pages_to_review.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# all pages from the latest batch with a no-consensus box\n",
    "suspect_subset = results_df_current_batch[results_df_current_batch['worker_id'].isin(suspect_workers[:5])]\n",
    "amt_util.write_results_df(suspect_subset)\n",
    "pages_to_review = pd.unique(suspect_subset['page'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Merging latest round of HITs into combined dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Load prior complete dataset if not in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_pickled_dir = './store_hit_results_metadata/question_anno/group_latest_combined/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "combined_results_df = pd.read_pickle(data_pickled_dir + 'complete_df.pkl')\n",
    "combined_consensus_df = pd.read_pickle(data_pickled_dir + 'consensus_df.pkl')\n",
    "combined_consensus_with_workerid_df = pd.read_pickle(data_pickled_dir + 'consensus_df_w_workers.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "amt_util.count_pages_in_df(combined_consensus_with_workerid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Updating full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "combined_results_df = results_df_question_batch\n",
    "combined_consensus_df = consensus_results_df_complete\n",
    "combined_consensus_with_workerid_df = consensus_with_workerid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Working with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "no_consensus_hits = combined_consensus_df[combined_consensus_df['category'] == 'No Consensus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "flaw_rate = len(no_consensus_hits) / len(combined_consensus_df)\n",
    "print 'text boxes without consensus are ' + '{0:0.2f}% '.format(flaw_rate * 100) + 'of the total'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "worker_quality_df[worker_quality_df['submitted'] > 50].sort_values('flaw_ratio', ascending= True).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bad_and_prolific_workers[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After looking through the top few offenders, it's clear that \n",
    "\n",
    "1. the very worst intentionally submitted many blank pages\n",
    "\n",
    "2. the rest didn't read the directions very closely\n",
    "\n",
    "3. I'm comfortable rejecting the work of those with > 100 submissions\n",
    "\n",
    "4. I'll ban the worst 15 from future HITs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "amt_util.write_results_df(combined_consensus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# all pages from the complete\n",
    "pages_to_review =pd.unique(combined_consensus_df['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# all pages from the complete dataset with a no-consensus box\n",
    "pages_to_review =pd.unique(no_consensus_hits['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# all pages from the latest batch with a no-consensus box\n",
    "suspect_subset = combined_results_df[combined_results_df['worker_id'].isin(bad_and_prolific_to_review[10:15])]\n",
    "amt_util.write_results_df(suspect_subset)\n",
    "pages_to_review = pd.unique(suspect_subset['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "sampling_rate = 0.2\n",
    "sample_size = int(len(pages_to_review) * sampling_rate)\n",
    "sampled_pages_to_review = list(np.random.choice(pages_to_review, size= sample_size, replace=False))\n",
    "print 'sampling ' + str(sample_size) + ' pages out of ' + str(len(pages_to_review))\n",
    "to_review = ['start_seq'] + sampled_pages_to_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "amt_util.review_results(to_review)\n",
    "print 'posting to review tool, navigate to http://localhost:8080/ to see the sampled consensus results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worker Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Basic worker stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "consensus_with_workerid_df = amt_util.make_consensus_df_w_worker_id(results_df_question_batch, consensus_results_df_current_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print 'number of unique workers:', pd.unique(results_df_question_batch['worker_id']).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_ = results_df_question_batch['worker_id'].value_counts().hist(bins= 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### HIT duration for pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "task_duration_seconds = []\n",
    "for hit_id, assignments in assignment_results_current_batch.items():\n",
    "    for assignment in assignments:\n",
    "        hit_duration = dt_parse.parse(assignment.SubmitTime) - dt_parse.parse(assignment.AcceptTime)\n",
    "        task_duration_seconds.append(hit_duration.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "task_duration_series = pd.Series(task_duration_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_ = task_duration_series.hist(bins=30, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "winsorized_durations = [t for t in task_duration_seconds if t < 150]\n",
    "w_duration_series = pd.Series(winsorized_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_ = pd.Series(w_duration_series).hist(bins=60)\n",
    "plt.title('Worker task duration', fontsize=50, verticalalignment='bottom', color = b16_colors.b)\n",
    "plt.ylabel(\"Number of Workers\", fontsize=30, labelpad=10, color = b16_colors.b)\n",
    "plt.xlabel(\"Seconds Spent on HIT\", fontsize=30, labelpad=10, color = b16_colors.b)\n",
    "plt.tick_params(axis='x', which='major', labelsize=20)\n",
    "plt.tick_params(axis='y', which='major', labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dur_mode = w_duration_series.mode().values[0]\n",
    "dur_median = w_duration_series.median()\n",
    "print 'duration mode= ' + str(dur_mode)\n",
    "print 'duration median= ' + str(dur_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### HIT pricing check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'd like the effective hourly rate to be between 10-12 dollars. This is considered equitable in the world of mechanical turk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hits_per_hour_high = 3600 / dur_mode\n",
    "hits_per_hour_low = 3600 / dur_median\n",
    "print 'effective hourly rate = $', hits_per_hour_low * static_params['amount'], 'to' , hits_per_hour_high * static_params['amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying high and low consensus workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "worker_conflicts = consensus_with_workerid_df[consensus_with_workerid_df['category'] != consensus_with_workerid_df['consensus_category']]\n",
    "all_worker_counts = results_df_question_batch['worker_id'].value_counts()\n",
    "bad_worker_counts = worker_conflicts['worker_id'].value_counts()\n",
    "worker_quality_df = pd.DataFrame([all_worker_counts, bad_worker_counts]).T\n",
    "worker_quality_df.columns=['submitted', 'incorrect']\n",
    "worker_quality_df['flaw_ratio'] = worker_quality_df['incorrect']/worker_quality_df['submitted']\n",
    "good_workers = worker_quality_df.sort_values('flaw_ratio', ascending= True).index.tolist()\n",
    "\n",
    "worker_quality_df.sort_values('flaw_ratio', ascending= True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "good_and_prolific_workers = worker_quality_df.sort_values('flaw_ratio', ascending= True).head(10).index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I became concerned that I missed the perfect performers, but as I suspected perfect workers only did 1-2 HITs at most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# aw_set = set(all_worker_counts.index)\n",
    "# bw_set = set(bad_worker_counts.index)\n",
    "# flawless_workers = list(aw_set.difference(bw_set))\n",
    "# all_worker_counts[all_worker_counts.index.isin(best_workers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bad_and_prolific_workers = worker_quality_df.sort_values('flaw_ratio', ascending= False).head(25).sort_values('incorrect', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bad_and_prolific_to_review = list(bad_and_prolific_workers[:5].index)\n",
    "really_bad_workers_to_review = list(really_bad_workers[:5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bad_and_prolific_workers.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "really_bad_workers = bad_and_prolific_workers[bad_and_prolific_workers['flaw_ratio'] > 0.5]\n",
    "really_bad_workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "bad worker decisions-\n",
    "\n",
    "1- didn't read directions\n",
    "\n",
    "2- many blank pages\n",
    "\n",
    "3- many blank pages\n",
    "\n",
    "4- incomplete\n",
    "\n",
    "the really bad workers are largely incomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Email contact with workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "turkers_contacted_me = turkmail_util.get_latest_worker_communication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "turkers_contacted_me = [w_id[0] for w_id in turkers_contacted_me.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "turkers_contacted_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "good_set = set(good_and_prolific_workers)\n",
    "bad_set = set(bad_and_prolific_to_review)\n",
    "contact_set = set(turkers_contacted_me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print good_set.intersection(contact_set)\n",
    "print bad_set.intersection(contact_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Messaging workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "subject = \"More science book annotation HITs are available\"\n",
    "message = \"\"\"\n",
    "Hello, \n",
    "\n",
    "If you're receiving this message you were among the top performers on the first group HITs I submitted.\n",
    "I've submitted another group of HITs, with more to follow in the next few days. \n",
    "I've added some additional instructions, and have removed the default instruction page (they can still be accessed by Read\n",
    "Instruction Button).\n",
    "\n",
    "Happy to get any feedback you might have for the new HITs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# _ = mturk.notify_workers(good_workers[:20], subject, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **HIT end-of-life**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pickle latest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#reset as needed\n",
    "# gn = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "next_group = gn + 1\n",
    "group_n = '_' + str(gn) + '/'\n",
    "\n",
    "temp_store_dir = './store_hit_results_metadata/question_anno/group'\n",
    "try:\n",
    "    os.mkdir(temp_store_dir + group_n)\n",
    "except:\n",
    "    OSError\n",
    "    \n",
    "result_file_name = 'hit_info.pkl'\n",
    "assignment_file_name = 'assignment_info.pkl'\n",
    "raw_results_file_name = 'raw_res.pkl'\n",
    "complete_results_file = 'complete_df.pkl'\n",
    "consensus_results_file = 'consensus_df.pkl'\n",
    "\n",
    "amt_util.pickle_this(r_hits_current_batch, temp_store_dir + group_n + result_file_name)\n",
    "amt_util.pickle_this(assignment_results_current_batch, temp_store_dir + group_n + assignment_file_name)\n",
    "amt_util.pickle_this(results_df_question_batch, temp_store_dir + group_n + raw_results_file_name)\n",
    "# results_df_current_batch.to_pickle(temp_store_dir + group_n + complete_results_file)\n",
    "consensus_results_df_current_batch.to_pickle(temp_store_dir + group_n + consensus_results_file)\n",
    "print 'saved HIT batch number ' + str(gn)\n",
    "print 'now onto batch ' +str(next_group) \n",
    "gn = next_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pickle combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "temp_store_dir = './store_hit_results_metadata/question_anno/group'\n",
    "group_n = '_latest_combined/'\n",
    "try:\n",
    "    os.mkdir(temp_store_dir + group_n)\n",
    "except:\n",
    "    OSError\n",
    "    \n",
    "complete_results_file = 'complete_df.pkl'\n",
    "consensus_results_file = 'consensus_df.pkl'\n",
    "consensus_results_file_w_workers = 'consensus_df_w_workers.pkl'\n",
    "\n",
    "combined_results_df.to_pickle(temp_store_dir + group_n + complete_results_file)\n",
    "combined_consensus_df.to_pickle(temp_store_dir + group_n + consensus_results_file)\n",
    "combined_consensus_with_workerid_df.to_pickle(temp_store_dir + group_n + consensus_results_file_w_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Accepting and deleting HITs... careful with these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### rejecting HITS, banning bad workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Uncomment only when ready to accept or delete hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def reject_bad_assignments(rejected_assignment_ids, rejected_worker_ids):\n",
    "    for assignment in rejected_assignment_ids:\n",
    "        mturk.reject_assignment(assignment)\n",
    "        \n",
    "        rejection_message_subject = \"One of your HITs was rejected\"\n",
    "        \n",
    "        rejection_message = \"\"\"\n",
    "        Your HIT was rejected because it was either incomplete or largely incorrect.\n",
    "        \"\"\"\n",
    "        \n",
    "        mturk.notify_workers(rejected_worker_ids, rejection_message_subject, rejection_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "workers_to_ban = bad_and_prolific_workers[:2].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "workers_to_ban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "number_rejected_assignments, number_rejected_workers = amt_util.reject_assignments(mturk, workers_to_ban, combined_consensus_with_workerid_df)\n",
    "print 'rejecting ' + str(number_rejected_assignments) + ' assignments' + ' from ' + str(number_rejected_workers) + ' workers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# assignments_to_accept = []\n",
    "assignment_status = []\n",
    "for hit_id, assignments in assignment_results_after_rejects.items():\n",
    "    for assignment in assignments:\n",
    "        assignment_status.append(assignment.AssignmentStatus)\n",
    "        if assignment.AssignmentStatus == 'Submitted':\n",
    "            assignments_to_accept.append(assignment)\n",
    "status_series = pd.Series(assignment_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "r_hits_after_rejects = amt_util.get_completed_hits(mturk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "assignment_results_after_rejects = amt_util.get_assignments(mturk, r_hits_after_rejects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### accepting HITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# amt_util.accept_hits(mturk, assignment_results_after_rejects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### deleting all HITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# amt_util.delete_all_hits(mturk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
